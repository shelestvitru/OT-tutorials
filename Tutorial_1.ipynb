{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manyasha-n-m/OT-tutorials/blob/main/Tutorial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJJ03Rz6f6Kr"
      },
      "source": [
        "## Hands-on Tutorials on Computational Optimal Transport\n",
        "### Instructor: Nataliia Monina\n",
        "-----\n",
        "\n",
        "### 1. Optimal Transport in discrete setting: examples\n",
        "In this notebook, we'll:\n",
        "1. Learn the basics of discrete Optimal Transport (OT) with and without regularization\n",
        "2. Explore how the regularization parameter affects solutions (Plans)\n",
        "3. Compute averages of measures/pictures via Wasserstein barycenters and compare them with Euclidean means.\n",
        "\n",
        "\n",
        "\n",
        "In this introduction tutorial, we will fix some notations and consider basic implementations possibly used in later sessions.\n",
        "\n",
        "Key initial points:\n",
        "\n",
        "- `POT` library -- already implemented code examples for solving/approximating Optimal Transort plans.\n",
        "- Demonstration on 2 main (simple-case) examples: for $\\mathbb{R}^1$ and for $\\mathbb{R}^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yhQw0EFjkXDF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "# !pip install POT --quiet\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ot\n",
        "import ot.plot\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9be9p0-ZkH3H"
      },
      "source": [
        "# General objects:\n",
        "\n",
        "### Space of coordinates\n",
        "- $X = \\{x_0,\\dots, x_{n-1}\\}, ~ Y = \\{y_0,\\dots, y_{m-1}\\}$ -- Sets of points in $\\mathbb{R}^d$.\n",
        "\n",
        "\n",
        "### Probability distributions\n",
        "- $\\mu = (\\mu_0, \\dots, \\mu_{n-1}), ~\\nu =  (\\nu_0, \\dots, \\nu_{m-1})$ -- Probability distributions on $X$ and $Y$, respectively \\\\\n",
        "In this notation, we can say that the \"probability\" of the object to be at the point $x_i$ is equal to $\\mu_i$.\n",
        "\n",
        "\n",
        "### Cost matrix\n",
        "- $C = \\begin{pmatrix} C_{00} & \\dots & C_{0 (m-1)}\\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "C_{(n-1)0} & \\dots & C_{(n-1)(m-1)}\n",
        "\\end{pmatrix}$ -- $C_{ij}$ tells how much we would \"pay\" to transport a unit of mass from the point $x_i$ to $y_j$.\n",
        "\n",
        "\n",
        "### Let's now visualize some of them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yONZZu0ktWf"
      },
      "source": [
        "### Example 1: $\\mathbb R^1$ Gaussians and Coulomb-like cost\n",
        "$c_1(x,y) = \\frac{1}{1+|x-y|}$, e.g. $C_1[i,j] = \\frac{1}{(1+ |X_1[i]-Y_1[j]|)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAMyxeM-mS_K"
      },
      "outputs": [],
      "source": [
        "'''Example 1'''\n",
        "\n",
        "X_1 = np.linspace(0,4, 51)\n",
        "Y_1 = np.linspace(0,4, 51)\n",
        "\n",
        "def discrete_gaussian(mean, variance, interval):\n",
        "    f = np.exp(-(interval-mean)**2/(2*variance)) / np.sqrt(2*np.pi*variance)\n",
        "    return f/f.sum()\n",
        "\n",
        "mu_1 = discrete_gaussian(1, 0.1, X_1)\n",
        "nu_1 = discrete_gaussian(2.8, 0.06, Y_1)\n",
        "\n",
        "'''Example 1: Test measures'''\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(X_1, mu_1, 'o', label=\"mu_1\")\n",
        "plt.plot(Y_1, nu_1, '+', label=\"nu_1\")\n",
        "plt.legend(loc=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjr8j5V4jpR-"
      },
      "outputs": [],
      "source": [
        "'''Example 1: Coulomb cost '''\n",
        "\n",
        "C_1 = 1 / (1 + np.abs(X_1[:, None] - Y_1[None, :]))\n",
        "\n",
        "# How does it look like?\n",
        "plt.figure(3)\n",
        "plt.imshow(C_1)\n",
        "\n",
        "# the biggest values are on the diagonal and decay away from the diagonal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm2Qod_XvAMN"
      },
      "source": [
        "Side comment: the numbers 0, 1, 2, ... and so on on this plots represent the indeces of the points in our spaces $X$ or $Y$. The upper left corner corresponds to $(x_0, y_0)$ up to the bottom right corner $(x_{n-1}, y_{m-1})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-CL32-UmsXJ"
      },
      "source": [
        "### Example 2: $\\mathbb R^2$ points and distance square\n",
        "$c_2(x,y) = ||x-y||^2$,  e.g. $C_2[i,j] = ||X_2[i]-Y_2[j]||^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB8C_ChfnRjQ"
      },
      "outputs": [],
      "source": [
        "''' Example 2'''\n",
        "\n",
        "X_2 = np.array([[1, 2],\n",
        "                [3, 1],\n",
        "                [1.5, 1.5],\n",
        "                [3, 2],\n",
        "                [2.5, 5],\n",
        "                [3.5, 4],\n",
        "                [1, 4],\n",
        "                [5, 2.5]])\n",
        "\n",
        "Y_2 = np.array([[8, 10],\n",
        "                [6.5, 1.5],\n",
        "                [6, 2],\n",
        "                [9.5, 7],\n",
        "                [9, 4],\n",
        "                [6, 6],])\n",
        "\n",
        "'''Example 2: Random valued test measures'''\n",
        "np.random.seed(0)\n",
        "# random values of mass at points of X_2 and Y_2, respectively\n",
        "rand_21 = np.random.randint(1, 10, size=len(X_2))\n",
        "rand_22 = np.random.randint(1, 10, size=len(Y_2))\n",
        "\n",
        "# normalize the mass into \"probabilities\"\n",
        "mu_2 = rand_21/rand_21.sum()\n",
        "nu_2 = rand_22/rand_22.sum()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "ax.grid()\n",
        "ax.plot(X_2[:, 0], X_2[:, 1], '+b', label='mu_2')\n",
        "\n",
        "for i, val in enumerate (mu_2):\n",
        "    ax.annotate(f'{val:.2f}', X_2[i])\n",
        "\n",
        "plt.plot(Y_2[:, 0], Y_2[:, 1], 'xr', label='nu_2')\n",
        "for i, val in enumerate (nu_2):\n",
        "    ax.annotate(f'{val:.2f}', Y_2[i])\n",
        "\n",
        "ax.legend(loc=0)\n",
        "ax.set(xlabel='1-axis')\n",
        "ax.set(ylabel='2-axis')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKZFQDt8wdoE"
      },
      "outputs": [],
      "source": [
        "'''Example 2: Distance squared'''\n",
        "\n",
        "C_2 = ot.dist(X_2, Y_2, metric='sqeuclidean')\n",
        "\n",
        "# C[i, j] tells you how much we \"pay\" to transfer mass from the point X[i]=(x1, x2) to Y[j]=(y1, y2)\n",
        "\n",
        "plt.figure(4)\n",
        "plt.imshow(C_2)\n",
        "\n",
        "print(f\"1-axis has: {len(X_2)} points -- number of points from X\")\n",
        "print(f\"2-axis has: {len(Y_2)} points -- number of points from Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzHKc3WmrU9t"
      },
      "source": [
        "# OT objects:\n",
        "### Couplings of $\\mu$ and $\\nu$ (or joint probability distributions)\n",
        "- $P = \\begin{pmatrix} P_{00} & \\dots & P_{0 (m-1)}\\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "P_{(n-1)0} & \\dots & P_{(n-1)(m-1)}\n",
        "\\end{pmatrix}$ -- possible \"coupling\" between $\\mu$ and $\\nu$, i.e. such that $\\sum\\limits_{i=0}^{n-1} P_{ij} = \\nu_{j}$ and $\\sum\\limits_{j=0}^{m-1} P_{ij} = \\mu_i$.\n",
        "\n",
        "- One of the ways to view $P_{ij}$ is: How much mass we will take from the point $x_i$ and send to $y_j$.\n",
        "\n",
        "- Another viewpoint: $P_{ij}$ says what is the \"probability\" of the object to be at the point $(x_i,y_j)$.\n",
        "\n",
        "\n",
        "## What do we want to compute (approximate) in Optimal Transport?\n",
        "\n",
        "- $P^*\\in argmin \\{F_C(P) := \\sum\\limits_{i=0}^{n-1}\\sum\\limits_{j=0}^{m-1}C_{ij}P_{ij} \\,:\\, P_{ij}\\geq 0, \\, \\sum\\limits_{i=0}^{n-1} P_{ij} = \\nu_{j}, \\, \\sum\\limits_{j=0}^{m-1} P_{ij} = \\mu_i\\}$\n",
        "\n",
        "- **Remark:** From now on, it doesn't matter \"what\" are the coordinates where our \"mass\" is, so the *dimension of $X$ or $Y$ is not relevant*. Everything necessary is already encoded in $\\mu, ~\\nu$ and $C$.\n",
        "\n",
        "Let's plot the examples of $P$. It is very nice to look at those big matrices in terms of heatmaps. In the pictures below, each pixel of the \"square\" contains a value: \"How much mass to take from $x_i$ and move to $y_j$\", so it is simply a color representation of the matrix $P$.\n",
        "\n",
        "Also, if you sum the matrix vertically, you will get the graph on the top -- distribution $\\nu$. Similarly, if you sum horizontally, we get the graph on the left -- distrubution $\\mu$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN6k2wHQmSNm"
      },
      "source": [
        "### **Fact**: if you take a matrix $P_{ij} = \\mu_i \\times \\nu_{j}$, it always satisfies the \"marginal\" conditions\n",
        "##### However, this particular $P$ is never the best solution for the Optimal Transport problem\n",
        "\n",
        "### Example 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhB5m77mmRcK"
      },
      "outputs": [],
      "source": [
        "P_1_bad = mu_1[:, None] * nu_1[None, :]\n",
        "\n",
        "plt.figure(5, figsize=(7,7))\n",
        "ot.plot.plot1D_mat(mu_1, nu_1, P_1_bad) # main method for visualizing plans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8r0Ro2xsrDa"
      },
      "source": [
        "**Important fact:** typically, the best solution will look almost like a \"line\" or a \"curve\" when you look at the picture. It can help us to see \"how good\" we are estimating the solution, more or less it is a \"sanity check\".\n",
        "\n",
        "For this time being, we can use some already implemented methods available in the `POT` library.\n",
        "\n",
        "### **First method**: solve the original problem (via Linear Programming, e.g., `POT` library)\n",
        "\n",
        "- Pros: provides the best approximation to the solution of the problem.\n",
        "\n",
        "- Cons: takes very long to compute, cannot use any gradient methods and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfQ8P90kyEuO"
      },
      "outputs": [],
      "source": [
        "P_1_best = ot.emd(mu_1, nu_1, C_1)\n",
        "\n",
        "plt.figure(7, figsize=(7,7))\n",
        "ot.plot.plot1D_mat(mu_1, nu_1, P_1_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj3eon3v2sP2"
      },
      "source": [
        "Coulomb cost is actually more interesting when the marginals are identical\n",
        "\n",
        "Let's see what happens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TndsVh6ywEVR"
      },
      "outputs": [],
      "source": [
        "P_1_best_same_marginals = ot.emd(mu_1, mu_1, C_1)\n",
        "\n",
        "plt.figure(7, figsize=(7,7))\n",
        "ot.plot.plot1D_mat(mu_1, mu_1, P_1_best_same_marginals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4qxTUE5Opnw"
      },
      "source": [
        "#### Exercises:\n",
        "\n",
        "- Example 1:\n",
        "    1. Generate distance squared for Example 1 and look at the solutions of OT for pairs (`mu_1`, `nu_1`) and (`mu_1`, `mu_1`) with this cost\n",
        "    3. (Optional) for fixed `mu` consider a \"moving\" `nu`. i.e., an array of several `[nu_0, nu_1,...,nu_k]`and compare solutions between (`mu`, `nu_j`). Then try a different cost and repeat\n",
        "        \n",
        "- Example 2:\n",
        "    1. Solve OT for our 2d (Example 2) here for C_2 and (`mu_2`, `nu_2`)\n",
        "\n",
        "- Both examples: compare the values of $F_C$(P_bad), e.g., product measure, and $F_C$(P_best), e.g., solution by `ot.emd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsC_T1P-OoR0"
      },
      "outputs": [],
      "source": [
        "''' Example 1'''\n",
        "# Your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjsxMulkOLpV"
      },
      "outputs": [],
      "source": [
        "'''Example 2'''\n",
        "# Your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUlFCbiKc1Tq"
      },
      "outputs": [],
      "source": [
        "'''Both examples: comparison of values of OT'''\n",
        "# Your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZvSugI3vHAI"
      },
      "source": [
        "### **Second method**: solve the regularized problem (Sikhorn algorithm). (Can still use `POT` here for now)\n",
        "\n",
        "Fix $\\varepsilon>0$. Now instead we are looking for a solution of\n",
        "\n",
        "$P^{\\varepsilon}\\in argmax \\{F^{\\varepsilon}_C(P) := \\sum\\limits_{i=0}^{n-1}\\sum\\limits_{j=0}^{m-1}C_{ij}P_{ij} +\\varepsilon \\sum\\limits_{i=0}^{n-1}\\sum_{j=0}^{m-1} P_{ij}(\\log P_{ij}-1)\\,:\\, P_{ij}\\geq 0, \\, \\sum\\limits_{i=0}^{n-1} P_{ij} = \\nu_{j}, \\, \\sum\\limits_{j=0}^{m-1} P_{ij} = \\mu_i\\}$\n",
        "\n",
        "\n",
        "\n",
        "- Pros: can define a nice algorithm that is faster to compute, provides approximation to the solution of the problem for $\\varepsilon$ small enough.\n",
        "\n",
        "- Cons: the solution is never exact, may get to the point when there is a division by almost 0.\n",
        "\n",
        "Let's solve the problem for different values of $\\varepsilon$ to see how it affects the solutions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KfvdSYvOssH"
      },
      "outputs": [],
      "source": [
        "# helpful function to plot and analyze and compare our solutions\n",
        "def analyze_solutions(mu, nu, P_computed, P_for_compare, epsilon, C):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    mu: np.ndarray\n",
        "        Actual measure mu\n",
        "    nu: np.ndarray\n",
        "        Actual measure nu\n",
        "    P_computed: np.ndarray\n",
        "        Computed plan P with the chosen method\n",
        "    P_for_compare: np.ndarray\n",
        "        Reference plan P to compare with (e.g., output of ot.emd)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    plt.figure\n",
        "        Plot of comparisons for our computed solution\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "    # error of marginals\n",
        "    # mu vs. output\n",
        "    ax[0].plot(mu)\n",
        "    ax[0].plot(np.sum(P_computed, axis=1))\n",
        "    ax[0].set_title('mu vs P_computed_mu')\n",
        "    # nu vs. output\n",
        "    ax[1].plot(nu)\n",
        "    ax[1].plot(np.sum(P_computed, axis=0))\n",
        "    ax[1].set_title('nu vs P_computed_nu')\n",
        "\n",
        "    # comparison of plans\n",
        "    ax[2].imshow(P_computed)\n",
        "    ax[2].set_title(f\"P_computed (eps={epsilon})\")\n",
        "    ax[3].imshow(P_for_compare)\n",
        "    ax[3].set_title(f\"P_for_compare (eps={epsilon})\")\n",
        "\n",
        "    print(\"Cost of P_computed:\", np.einsum('ij,ij', C, P_computed))\n",
        "    print(\"Cost of P_for_compare:\", np.einsum('ij,ij', C, P_for_compare))\n",
        "    return ax\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xAVnXH1jJy9"
      },
      "outputs": [],
      "source": [
        "epsilon = 0.01\n",
        "\n",
        "P_001 = ot.sinkhorn(mu_1, nu_1, C_1, epsilon)\n",
        "\n",
        "analyze_solutions(mu_1, nu_1, P_001, P_1_best, epsilon, C_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThtKP3v31a1F"
      },
      "source": [
        "## Role of $\\varepsilon$: how much it affects the solution?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4LXXGlldX2b"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact\n",
        "\n",
        "def explore_eps(eps=0.001):\n",
        "    P_different_eps = ot.sinkhorn(mu_1, nu_1, C_1, eps)\n",
        "    return analyze_solutions(mu_1, nu_1, P_different_eps, P_1_best, epsilon, C_1)\n",
        "\n",
        "interact(explore_eps, eps=(0.001, 0.1, 0.001));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlPD1fFQgZjh"
      },
      "outputs": [],
      "source": [
        "'''Place to play around with different measures, costs and other parameters'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4X7polm75z2"
      },
      "source": [
        "### Wasserstein Barycenters\n",
        "\n",
        "Optimal transport plays a crucial part in numerical methods for comparing measure-like objects. It gives nice geometrical interpretations of distances and averages between probability distributions. In this part we will compare Euclidean and Wasserstein barycenters (weigthed averages) of 1d measures and pictures (as 2d measures)\n",
        "\n",
        "Given probability distributions $ \\mu^1, \\dots, \\mu^N $ and weights $ \\lambda_1, \\dots, \\lambda_N \\geq 0 $ with $ \\sum_i \\lambda_i = 1 $, the **Wasserstein barycenter** is the \"average\" distribution $ \\nu $ that minimizes\n",
        "\n",
        "$$\n",
        "\\nu^* = \\arg\\min_\\nu \\sum_{k=1}^N \\lambda_k W_2(\\nu, \\mu^k),\n",
        "$$\n",
        "\n",
        "where (in discrete setting):\n",
        "- $ W_2^2(\\nu, \\mu) = min \\{\\sum_{ij}P_{ij} C_{ij} : \\sum_j P_{ij}=\\mu_i, \\sum_i P_{ij}=\\nu_j\\} $ is the **Wasserstein distance**\n",
        "- $ C_{ij} = d(x_i,y_j)^2 $ is the cost function induced by a distance.\n",
        "- Often solved with entropic regularization parameter $ \\varepsilon > 0 $, e.g. basically involving Sinkhorn algorithm\n",
        "\n",
        "\n",
        "Unlike a **pixelwise (Euclidean) average**\n",
        "$$ \\tilde \\mu = \\frac1N\\sum_{k=1}^N\\mu^k$$\n",
        "which simply blends intensities, the Wasserstein barycenter:\n",
        "- **Moves mass** to align structures (e.g., shifts strokes in digits),\n",
        "- Produces a result that is **sharper and more meaningful** as a \"typical\" element.\n",
        "\n",
        "---\n",
        "\n",
        "#### How `ot.bregman.barycenter` works?\n",
        "\n",
        "POT’s `ot.bregman.barycenter` iteratively computes the *entropy-regularized* (for $\\varepsilon>0$) Wasserstein average of several distributions by solving many small Sinkhorn OT problems and blending the results. The entropic regularization makes it fast and smooth, so we can use it on images like MNIST easily.\n",
        "\n",
        "**However, due to regularization, entropic barycenter has errors (you can see even when choosing $\\lambda=0$  or 1)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul_36uCHzkXl"
      },
      "source": [
        "#### Example $\\mathbb R^1$\n",
        "Let's compute barycenter for measures `mu_1` and `nu_1` from Example 1 but with distance squared.\n",
        "We shall assume, for simplicity, that they are defined on the **same** interval and with the same number of discretization points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjAPvF9YzgAx"
      },
      "outputs": [],
      "source": [
        "'''Example 1'''\n",
        "\n",
        "# take C as distance squared\n",
        "\n",
        "C = ot.dist(X_1[:, None], Y_1[:, None])\n",
        "eps = 0.009\n",
        "\n",
        "def compare_barycenter(lambda_=0.5):\n",
        "    \"\"\"lambda_ = weight for mu (nu gets 1-lambda_)\"\"\"\n",
        "    weights = np.array([lambda_, 1-lambda_])\n",
        "\n",
        "    # Stack the distributions (flattened vectors)\n",
        "    A = np.array([mu_1, nu_1])\n",
        "\n",
        "    # Compute Wasserstein barycenter (entropic)\n",
        "    w_bary = ot.bregman.barycenter(A.T, C, reg=eps, weights=weights)\n",
        "\n",
        "    # Compute Euclidean barycenter (simple weighted average)\n",
        "    e_bary = lambda_*mu_1 + (1-lambda_)*nu_1\n",
        "\n",
        "    # Plot everything\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    axes[0].plot(X_1, mu_1, label=\"mu\")\n",
        "    axes[0].plot(X_1, nu_1, label=\"nu\")\n",
        "    axes[0].plot(X_1, e_bary, label=\"e_bary\")\n",
        "    axes[0].legend()\n",
        "    axes[1].plot(X_1, mu_1, label=\"mu\")\n",
        "    axes[1].plot(X_1, nu_1, label=\"nu\")\n",
        "    axes[1].plot(X_1, w_bary, label=\"w_bary\")\n",
        "    axes[1].legend()\n",
        "\n",
        "\n",
        "interact(compare_barycenter, lambda_=(0.0, 1.0, 0.05));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXj6YvsHzo2S"
      },
      "source": [
        "#### Example with Mnist dataset\n",
        "\n",
        "Here we will choose several samples of a number from Mnist dataset and compute the picture \"on average\" by finding Euclidean and Wasserstein barycenter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsRcDrs98rfQ"
      },
      "outputs": [],
      "source": [
        "'''Example with mnist'''\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# x_train contains images, y_train contains names (labels) of the them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXIHwIOb8x9J"
      },
      "outputs": [],
      "source": [
        "'''Choose a mnist digit to experiment with'''\n",
        "\n",
        "digit = 7\n",
        "num_samples = 20  # how many samples to average\n",
        "indices = np.where(y_train == digit)[0][:num_samples]\n",
        "images = x_train[indices].astype(np.float32)\n",
        "\n",
        "# Normalize each image to be a probability distribution\n",
        "images = images / np.sum(images, axis=(1,2))[:, None, None]\n",
        "\n",
        "# let's plot them to see what they look like\n",
        "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(5):\n",
        "        axes[i,j].imshow(images[4*i+j], cmap=\"gray\")\n",
        "        axes[i,j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\"\"\"These are the samples that we want to average\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvoUm8wp-OwD"
      },
      "outputs": [],
      "source": [
        "# prepare sata for Wasserstein barycenter\n",
        "A = np.array([img.flatten() for img in images])  # shape (20, 784)\n",
        "weights = np.ones(len(images)) / len(images)  # uniform average\n",
        "\n",
        "# Build cost matrix (pixel coordinate distances)\n",
        "x = np.arange(28)\n",
        "X, Y = np.meshgrid(x, x)\n",
        "coords = np.stack([X.flatten(), Y.flatten()], axis=1, dtype=np.float64)\n",
        "C = ot.dist(coords, coords, metric='sqeuclidean')\n",
        "C /= C.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXbnqHLrHwDC"
      },
      "outputs": [],
      "source": [
        "# Entropic Wasserstein Barycenter\n",
        "w_bary = ot.bregman.barycenter(A.T, C, reg=0.0005, weights=weights)\n",
        "w_bary_img = w_bary.reshape(28, 28)\n",
        "\n",
        "# Comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "axes[0].imshow(np.mean(images, axis=0), cmap=\"gray\")\n",
        "axes[0].set_title(\"Euclidean Barycenter\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(w_bary_img, cmap=\"gray\")\n",
        "axes[1].set_title(\"Wasserstein Barycenter\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].imshow(images[0], cmap=\"gray\")\n",
        "axes[2].set_title(f\"One Sample of '{digit}'\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCnQpGdmJGAZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPBHnPTR3Y7CB5/MiilBvKF",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ot-tutorials",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
